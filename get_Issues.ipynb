{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad5df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02ef523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your GitHub username, repository name, and access token # timzzy deepTralog tensorflow\n",
    "username = \"framework username\"\n",
    "repository = \"framework repository name\"\n",
    "access_token = \"my github access token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185f74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#//\n",
    "def get_all_issues(username, repository, access_token):\n",
    "    issues = []\n",
    "    loop_count =0 \n",
    "    start_date_str = '2023-08-09'  # The start date\n",
    "    end_date_str = '2023-08-20'    # The end date\n",
    "\n",
    "    # Initialize headers with the access token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "\n",
    "    # Start with the first page of issues\n",
    "    url = f\"https://api.github.com/repos/{username}/{repository}/issues\"\n",
    "    params = {\"state\": \"all\", \n",
    "              \"per_page\": 100,\n",
    "              \"sort\": \"created\", #worked for issues\n",
    "              \"direction\": \"asc\", #worked for issues\n",
    "#               \"since\": start_date_str +'T00:00:00Z', #since worked for issues using last updated inclusive \n",
    "              \"until\": end_date_str + 'T23:59:59Z' #didnt work with issues\n",
    "             }  # You can adjust per_page as needed\n",
    "\n",
    "    while url :\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            issues.extend(response.json())\n",
    "            \n",
    "            \n",
    "            # Check if there are more pages\n",
    "            if \"Link\" in response.headers and 'rel=\"next\"' in response.headers[\"Link\"]:\n",
    "                url = response.links[\"next\"][\"url\"]\n",
    "            else:\n",
    "                url = None\n",
    "                \n",
    "#             loop_count+=1   \n",
    "#             #Break the loop after X-loop time\n",
    "#             if loop_count <2:\n",
    "#                break\n",
    "#                url = None  # the goal is to stop running the script after then\n",
    "                \n",
    "        else:\n",
    "            print(f\"Error: Unable to fetch issues. Status code: {response.status_code}\")\n",
    "            return []\n",
    "        time.sleep(4)\n",
    "    return issues\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract all the labels for an issue\n",
    "def get_labels_for_issue(owner, repo, issue_number, access_token):\n",
    "    headers_get_issue_label = {\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    url_get_issue_label = f'https://api.github.com/repos/{owner}/{repo}/issues/{issue_number}'\n",
    "    response_get_issue_label = requests.get(url_get_issue_label, headers=headers_get_issue_label)\n",
    "    \n",
    "    if response_get_issue_label.status_code == 200:\n",
    "        data_issue_label = response_get_issue_label.json()\n",
    "        labels_issue = [label_issue['name'] for label_issue in data_issue_label['labels']]\n",
    "        return labels_issue\n",
    "    else:\n",
    "        print(f\"Error: {response_get_issue_label.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ********************This function changes all the elements in an array to list\n",
    "def concatenate_arrayVal(arrayVal):\n",
    "    if isinstance(arrayVal, list):\n",
    "        concat_value = ', '.join(arrayVal)\n",
    "        return concat_value\n",
    "    else:\n",
    "        return []  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a807a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved as all_issues_keras.json\n"
     ]
    }
   ],
   "source": [
    "#save the issues\n",
    "try:\n",
    "    if __name__ == \"__main__\":\n",
    "        issue_file_name= \"all_issues_\" + repository\n",
    "        all_issues = get_all_issues(username, repository, access_token)\n",
    "        file_path = \"raw_json/\" + issue_file_name + \".json\"\n",
    "        with open(file_path, \"w\") as json_file:\n",
    "            json.dump(all_issues, json_file)\n",
    "        print(f\"successfully saved as {issue_file_name}.json\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred, could not save the file\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b35025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376b495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976bd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d25dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the required columns in the \n",
    "\n",
    "if all_issues:\n",
    "\n",
    "    # Extract relevant information from issues and create a DataFrame\n",
    "    issue_data = {\n",
    "        'Issue Number': [issue['number'] for issue in all_issues],\n",
    "        'Title': [issue['title'] for issue in all_issues],\n",
    "        'State': [issue['state'] for issue in all_issues],\n",
    "        'URL': [issue['html_url'] for issue in all_issues],\n",
    "        'ApI URL': [issue['url'] for issue in all_issues],\n",
    "        'Comment Count': [issue['comments'] for issue in all_issues],\n",
    "        'Comments URL': [issue['comments_url'] for issue in all_issues],\n",
    "        'Events URL': [issue['events_url'] for issue in all_issues],\n",
    "        'Created at': [issue['created_at'] for issue in all_issues],\n",
    "        'Last Updated': [issue['updated_at'] for issue in all_issues],\n",
    "        'Closed at': [issue['closed_at'] for issue in all_issues],\n",
    "        'Issue Labels': [concatenate_arrayVal(get_labels_for_issue(username, repository, issue['number'], access_token)) for issue in all_issues],\n",
    "    }\n",
    "else:\n",
    "    print(\"No Issue pulled from Repository\")\n",
    "\n",
    "\n",
    "# Make a dataframe\n",
    "df_all_issues = pd.DataFrame(issue_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f35b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           text_column\n",
      "0  apple banana cherry\n",
      "2           grape kiwi\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d0b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_env",
   "language": "python",
   "name": "phd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
